# -*- coding: utf-8 -*-
"""SentimentAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1291ooeKSl-mzT9GTL79tG_opoAsySv1s

# **Goal: Predict the sentiment of input text using different machine learning methods**

## **Supervised Learning Method**
#### - Random Forest
Random Forest is an ensemble learning method that operates by constructing multiple decision trees during training and outputs the class that is the mode of the classes of the individual trees.

#### - Naive Bayes
Naive Bayes is a probabilistic classifier based on Bayes' theorem with the "naive" assumption of independence between features. It is simple yet effective for sentiment analysis tasks.

#### - Logistic Regression
Logistic Regression is a linear classification algorithm used for binary classification tasks. It models the probability of the default class using the logistic function.

## **Fine-tuning Pre-trained Model**
#### - BERTopic Modeling
BERTopic is a topic modeling technique that leverages pre-trained BERT embeddings to perform clustering and topic modeling on textual data. By fine-tuning BERT embeddings on the sentiment analysis task, we can achieve state-of-the-art results.

## **Data Set**
1) Airline Sentiment -> Containing Positive and Negative Reviews
2) Review Polarity -> Containing Positive and Negative Folders


## **Data Pipeline**
### 1) Data Pre-processing
Data pre-processing is a crucial step in preparing the input data for modeling. This includes tasks such as:
- Tokenization: Breaking down the text into individual words or tokens.
- Removing stop words: Commonly used words that typically do not carry meaningful information.
- Lemmatization or stemming: Normalizing words to their base form to reduce sparsity and improve generalization.

### 2) Data Modeling
In this step, we train the machine learning models using the pre-processed data. This involves:
- Splitting the data into training and testing sets.
- Training each model using the training data.
- Fine-tuning hyperparameters using techniques such as cross-validation.
- Evaluating the models on the testing data.

### 3) Data Evaluation
After training the models, we evaluate their performance using various metrics such as:
- Accuracy: The proportion of correctly classified instances.
- Precision: The proportion of true positive predictions among all positive predictions.
- Recall: The proportion of true positive predictions among all actual positive instances.
- F1-score: The harmonic mean of precision and recall, providing a balanced measure between the two.

Additionally, we may visualize the results using confusion matrices, ROC curves, and precision-recall curves to gain insights into model performance and identify areas for improvement.
"""

import zipfile
zip_path = '/content/airline_sentiment_data.zip'
unzip_path = '/content'

# Open the zip file in read mode
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    # Extract all the contents into the directory
    zip_ref.extractall(unzip_path)

### Import the dataset

import pandas as pd

# Specify the encoding as 'latin-1'
df = pd.read_csv("/content/Tweets.csv", encoding='latin-1')

df

# Pre

"""### **Rough Implementation of BERT for Sentiment Analysis**

 - The example is found with this tutorial: [Link](https://www.analyticsvidhya.com/blog/2021/12/fine-tune-bert-model-for-sentiment-analysis-in-google-colab/#:~:text=Introduction%20to%20BERT%20Model%20for%20Sentiment%20Analysis&text=It%20is%20used%20to%20understand,negative%2C%20or%20neutral%20about%20it.)
"""

import tensorflow_datasets as tfds
(ds_train, ds_test), ds_info = tfds.load('imdb_reviews',
          split = (tfds.Split.TRAIN, tfds.Split.TEST),
          as_supervised=True,
          with_info=True)

!pip install -q transformers

from transformers import BertTokenizer
from transformers import TFBertForSequenceClassification
import tensorflow as tf


tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)


def convert_example_to_feature(review):
  return tokenizer.encode_plus(review,
                add_special_tokens = True, # add [CLS], [SEP]
                max_length = max_length, # max length of the text that can go to BERT
                pad_to_max_length = True, # add [PAD] tokens
                return_attention_mask = True, # add attention mask to not focus on pad tokens
              )

  # can be up to 512 for BERT
max_length = 512
batch_size = 6


def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):
  return {
      "input_ids": input_ids,
      "token_type_ids": token_type_ids,
      "attention_mask": attention_masks,
  }, label

def encode_examples(ds, limit=-1):
  # prepare list, so that we can build up final TensorFlow dataset from slices.
  input_ids_list = []
  token_type_ids_list = []
  attention_mask_list = []
  label_list = []
  if (limit > 0):
      ds = ds.take(limit)
  for review, label in tfds.as_numpy(ds):
    bert_input = convert_example_to_feature(review.decode())
    input_ids_list.append(bert_input['input_ids'])
    token_type_ids_list.append(bert_input['token_type_ids'])
    attention_mask_list.append(bert_input['attention_mask'])
    label_list.append([label])
  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)

# train dataset
ds_train_encoded = encode_examples(ds_train).shuffle(10000).batch(batch_size)
# test dataset
ds_test_encoded = encode_examples(ds_test).batch(batch_size)


# recommended learning rate for Adam 5e-5, 3e-5, 2e-5
learning_rate = 2e-5
# we will do just 1 epoch, though multiple epochs might be better as long as we will not overfit the model
number_of_epochs = 1
# model initialization
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')
# The number of epochs is set to 2 as higher epochs will give rise to overfitting problems as well as take more time for the model to train.
# choosing Adam optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)
# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')
model.compile(optimizer=optimizer, loss=loss, metrics=[metric])

test_sentence = "I love it so much"

predict_input = tokenizer.encode(test_sentence,

truncation=True,

padding=True,

return_tensors="tf")

tf_output = model.predict(predict_input)[0]
tf_prediction = tf.nn.softmax(tf_output, axis=1)
labels = ['Negative','Positive'] #(0:negative, 1:positive)
label = tf.argmax(tf_prediction, axis=1)
label = label.numpy()
print(labels[label[0]])

test_sentence = "I don't really like this at all!"

predict_input = tokenizer.encode(test_sentence,

truncation=True,

padding=True,

return_tensors="tf")

tf_output = model.predict(predict_input)[0]
tf_prediction = tf.nn.softmax(tf_output, axis=1)
labels = ['Negative','Positive'] #(0:negative, 1:positive)
label = tf.argmax(tf_prediction, axis=1)
label = label.numpy()
print(labels[label[0]])